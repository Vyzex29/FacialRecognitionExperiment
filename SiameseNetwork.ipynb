{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Siamese network notes:\n",
    " tf.keras.model for siamese network passing input and outputs\n",
    " (model(inputs=[inputImage, verificationImage], output = [1,0] - distance)\n",
    "\n",
    "layer types:\n",
    " Layer - allows defining a custom layer\n",
    "\n",
    " Conv2d - allows convolution :)\n",
    "\n",
    " Dense - fully connected layer\n",
    "\n",
    " MaxPooling2d - shrink our data\n",
    "\n",
    " Input - base class allows definiton of model inputs\n",
    "\n",
    " Flatter - allows to convert convolution into 1d array, which in turn allows to pass data into the Dense form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import packages and create folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plot\n",
    "import Configuration.Config as config\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer,Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf\n",
    "\n",
    "for path in config.siamese.values():\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdirs(path)\n",
    "        print(\"Created directory at: \" + path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Setting up GPU Growth memory limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Getting data - http://vis-www.cs.umass.edu/lfw/\n",
    "downloading lfw.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# unzip faces in the wild\n",
    "!cd Siamese && tar -xf lfw.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "negativePath = config.siamese['NEGATIVE_PATH']\n",
    "for dir in os.listdir('Siamese/lfw'):\n",
    "    for file in os.listdir(os.path.join('Siamese/lfw', dir)):\n",
    "        existingPath = os.path.join('Siamese/lfw', dir, file)\n",
    "        newPath = os.path.join(negativePath, file)\n",
    "        os.replace(existingPath, newPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Positive/Anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import PicturePipeline\n",
    "\n",
    "PicturePipeline.runSiamesePicturePipeline()\n",
    "# manualy split int onchors (webcam like) and positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Configuration.Config as config\n",
    "import uuid\n",
    "\n",
    "# from webcam\n",
    "anchorPath = config.siamese['ANCHOR_PATH']\n",
    "positivePath = config.siamese['POSITIVE_PATH']\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "   \n",
    "    #250 x 250\n",
    "    frame = frame[120:120+250,200:200+250, :]\n",
    "    \n",
    "    # a for anchor\n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        # Create the unique file path \n",
    "        imgname = os.path.join(anchorPath, '{}.jpg'.format(uuid.uuid1()))\n",
    "        # Write out anchor image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    # p for positive\n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        # Create the unique file path \n",
    "        imgname = os.path.join(positivePath, '{}.jpg'.format(uuid.uuid1()))\n",
    "        # Write out positive image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    cv2.imshow('Anchor/Positives', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "          \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loading/Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import Configuration.Config as config\n",
    "anchorPath = config.siamese['ANCHOR_PATH']\n",
    "positivePath = config.siamese['POSITIVE_PATH']\n",
    "negativePath = config.siamese['NEGATIVE_PATH']\n",
    "\n",
    "# this is only for 1 person\n",
    "\n",
    "anchorData = tf.data.Dataset.list_files(anchorPath+'\\*.jpg').take(380)\n",
    "positiveData = tf.data.Dataset.list_files(positivePath+'\\*.jpg').take(380)\n",
    "negativeData = tf.data.Dataset.list_files(negativePath+'\\*.jpg').take(380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "positiveDataset = tf.data.Dataset.zip((anchorData, positiveData, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchorData)))))\n",
    "negativeDataset = tf.data.Dataset.zip((anchorData, negativeData, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchorData)))))\n",
    "concatinatedDatasetForAPerson = positiveDataset.concatenate(negativeDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatinatedDatasetForAPerson = concatinatedDatasetForAPerson.map(tt.preProcessTwinImages)\n",
    "concatinatedDatasetForAPerson = concatinatedDatasetForAPerson.cache()\n",
    "concatinatedDatasetForAPerson = concatinatedDatasetForAPerson.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainingImageAmount = round(len(concatinatedDatasetForAPerson) * .7) # 70% of images\n",
    "trainingData = concatinatedDatasetForAPerson.take(trainingImageAmount)\n",
    "trainingData = trainingData.batch(16)\n",
    "trainingData = trainingData.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingData = concatinatedDatasetForAPerson.skip(trainingImageAmount) # taking the other 30 %\n",
    "testingImageAmount = round(len(concatinatedDatasetForAPerson) * .3)\n",
    "testingData = testingData.take(testingImageAmount)\n",
    "testingData = testingData.batch(16)\n",
    "testingData = testingData.prefetch(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}